# Java 并发编程总结 

[TOC]

## Frequently Asked Questions

### 多线程理论相关 FAQ
#### 为什么需要多线程编程？
1. 在单处理器系统中。使用多线程编程有助于提高系统吞吐量。当程序等待某个同步 I/O 操作完成时，使用单线程程序，处理器将处于空闲状态。而使用多线程程序中，一个线程在等待 I/O 操作完成，而另一个线程则可以继续运行。从而提高处理器资源利用率以提高系统吞吐量。
2. 在多处理器系统中。如果使用单线程程序将会浪费多余的处理器资源无法使用。使用多线程编程能充分利用多个处理器的资源利用率来提升系统吞吐量。
3. Amdahl 定律告诉我们，提高程序的加速比取决于将程序中串行部分转换成可并行部分的比重及其加速倍数。在多处理器系统中，使用多线程编程通常可将可并行执行部分的程序提高效率为核心数 N 倍。因此加速比 S = 1 /(1 - p + p/N)

#### 多线程引入了什么问题？
1. 安全性问题。
2. 活跃性问题。
3. 性能问题。

#### 什么是安全性问题，解决方案有哪些？
+ 安全性问题简言之就是在多线程并发访问过程中，程序不会发生错误的行为。

##### 什么是竞态条件 (race condition)
由于不恰当的执行时序而出现不正确的结果称之为竞态条件。（竞态条件一词出现在《并发编程实战》的译本中，其翻译正确性有待考证，杜绝以讹传讹）

##### 什么情况可能会发生线程安全问题？有哪些实现线程安全的技术？
当多个线程对处于共享的、可变的状态变量（对象实例或静态域）进行访问，可能会发生线程安全问题。”共享”意味着变脸够可以由多个线程同时访问，而“可变”则意味着变量的值在其生命周期内可以发生变化。
1. 使用正确的同步或互斥技术。正确的同步技术在 Java 中包括
   1. Java 监视器模式
   2. JUC 的 ReentrantLock 以及其他各种同步器。
   3. 利用硬件提供的原子的读-改-写技术。比如 CAS。
2. 线程封闭技术。
   1. Ad-hoc 线程封闭技术。即维护线程封闭性的职责完全由程序实现来承担。
   2. 栈封闭技术。由于访问局部变量和方法调用都是位于执行线程的栈中，其他线程无法访问这个栈。也就实现了线程安全。
   3. ThreadLocal 技术。ThreadLocal 能使线程中的某个值与保存值的对象关联起来。以实现线程安全。
      + 在 Java 中，Thread 类有一个 threadLocals 的 Map，这个 map 充当线程中的值，map 存放的是与线程关联的对象。key 是 ThreadLocal 类，value 是 Object。
3. 不可变技术。通过将共享的变量或对象实现为不可变的，使其多个线程访问时都是只读操作，也就实现了线程安全性。

#### 活跃性问题有哪些？
1. 死锁。死锁指的是多个线程分别持有一个资源，且都至少需要另一个被其他线程所持有的资源才能继续运行下去的现象。死锁发生后通常是需要关闭进程。（其他解决方案通常都开销较大）
2. 饥饿。饥饿是指当线程无法访问它所需要的资源而不能继续运行的现象。引发饥饿最常见资源就是 CPU 时钟周期。
3. 活锁。活锁是指处理消息的线程并没有阻塞，但却也无法取得实质上的进展，比如一直在失败-重试的无限循环。解决方案通常是在重试机制中引入随机性。
4. 信号丢失。
5. 糟糕的响应性。是指锁或资源被占有的时间过长，导致其他需要这个资源或锁的线程需要等待很长时间。比如同优先级的 CPU 密集型的后台任务与 GUI 的前台程序都在竞争 CPU，则有可能导致前台程序的响应性造成影响。或者某个大容器的迭代操作，将迭代较长时间，而在这期间内，其他访问这个容器的线程都在等待。

##### 试举出几个死锁的示例
1. 锁顺序死锁。两个线程试图以不同的顺序来获得相同的锁，则可能发生死锁。如下代码。
   ```
      void leftRight() {
         synchronized (left) {
            synchronized (right) {...}
         }
      }

      void rightLeft() {
         synchronized (right) {
            synchronized (left) {...}
         }
      }
   ```
2. 动态的锁顺序死锁。有时，并不能清楚地知道是否在锁顺序上有足够的控制权来避免死锁的发生。如下代码
   ```
      void leftRight(Object left, Object right) {
         synchronized (left) {
            synchronized (right) {...}
         }
      }
   ```
3. 在协作对象之间发生的死锁。如果在持有锁时调用某个也持有锁的外部方法，那么可能就会发生死锁问题。如下代码。
   ```
   class A {
      synchronized void invoke() {
         B.method();
      }
      synchronized void method() {...}
   }

   class B {
      synchronized void method() {...}
      synchronized void invoke() {
         A.method();
      }
   }
   ```
4. 资源死锁。当多个线程相互持有彼此正在等待的资源而又不释放自己已持有的资源时会发生死锁，比如数据库连接，如果一个任务需要连接两个数据库，并且请求这两个资源时不会始终遵循相同的顺序，那么可能发生死锁。

##### 根据上面锁描述的死锁示例，有哪些预防死锁的方法。
1. 如果所有线程以固定的顺序来获得锁，那么在程序中就不会出现锁顺序死锁问题。
2. 如果方法中有多个形参要作为锁来使用的话，并且具备可比较性，那么排序之后再进行顺序锁定，从而避免死锁。或者，在其多个形参锁锁定之前，附加一个锁，也可以避免死锁问题的发生。
3. 开放调用。如果在调用某个方法时不需要持有锁，那么这种调用被称为开放调用。在程序中应尽量使用开放调用。与那些在持有锁时调用外部方法的程序相比，更易于对依赖于开放调用的程序进行死锁分析。
4. 采用尝试获取或者超时获取锁，（超时）失败则放弃所有锁，然后退避一段时间后进行重试的策略来获取锁，从而预防死锁问题的发生。

##### 死锁诊断的工具有哪些？
1. 线程转储。一般线程等待状态信息字样会包含“waiting to lock ...”， 检查等待状态的线程有没有构成一个环路。
2. Java 自带的 visualvm 工具。

#### 多线程引入的性能开销有哪些？
1. 多线程协作。例如加锁、触发信号以及内存同步等。
2. 上下文切换。
3. 线程的创建与销毁。
4. 多线程的调度。

##### 上下文切换开销是什么？哪些原因会导致上下文切换？上下文切换过多会有什么问题？
+ 上下文切换是指操作系统在切换线程做的工作，这些工作包括
  + 假设 A 是需要被挂起的线程。保存线程 A 的现场，通常是保存程序计数器、栈指针、寄存器的值。
  + 将线程 A 挂起，放到队列中等待调度。
  + 从队列中选择另一个线程 B。
  + 恢复现场。将线程 B 的程序计数器、栈指针、寄存器的值填充到寄存器。
  + 另外，如果线程 A 和线程 B 访问的数据不同，可能会导致一些缓存缺失。
  + 另外，在大多数通用的处理器中，上下文切换的开销相当于 5000 ~ 10000 个时钟周期，大概是几微秒。
+ 导致上下文切换的原因有: 
  + 如果可运行的线程大于 CPU 的数量，某个 CPU 时间片运行到期，那么操作系统会将该线程调度出来，从而使其它线程能够使用 CPU。
  + 当线程由于等待某个发生竞争的锁、阻塞 I/O、条件变量上等待而被阻塞时，JVM 通常会将这个线程挂起，并允许它被交换出去。
+ 在程序中如果频繁地发生阻塞，那么它们就无法使用完整的调度时间片，与 CPU 密集型的程序就会发生越多的上下文切换，从而增加调度开销，并因此降低吞吐量。

##### 内存同步的开销主要是指什么？
+ 同步操作的性能开销包括多个方面。在 Synchronized 和 volatile 提供的可见性保证中可能会使用一些特殊指令，即内存栅栏。内存栅栏可以刷新缓存，使缓存无效，刷新硬件的写缓冲，以及停止执行管道。
+ 在评估同步操作带来的性能影响时，区分有竞争的同步和无竞争的同步非常重要。无竞争的同步的开销对应用程序整体性能的影响微乎其微，因为 JVM 通常都会对其进行优化。例如锁消除、锁粗化等技术。
+ 某个线程的同步可能会影响其他线程的性能。同步会增加共享内存总线上的通信量，总线的带宽是有限的，并且所有的处理器都将共享这条总线。如果有多个线程竞争同步带宽，那么所有使用了同步的线程都会受到影响。

#### 有哪些方式可以减少锁的竞争？
有两个因素将影响在锁上发生竞争的可能性
1. 锁的请求频率
2. 每次持有该锁的时间。

因此，减小锁的竞争主要有下面几种方式。
1. 缩小锁的范围。以尽可能缩短锁的持有时间。
2. 减小锁的粒度，以降低线程请求锁的频率。主要有锁分解、锁分段和避免热点域等技术实现。
3. 放弃使用独占锁。如果有可能的话。

#### 怎样使程序拥有更好的性能？
想要通过并发来获得更好的性能，需要努力做好两件事情。
1. 更有效地利用现有处理资源。即尽可能使 CPU 保持忙碌状态且是做有用的工作。
2. 在出现新的处理资源时使程序能够尽可能地利用这些新资源。即提高可伸缩性。

如果程序无法使现有的处理器保持忙碌状态，那么增加再多的处理器也无济于事。

#### 一个程序的性能的衡量指标主要有哪些？
1. 吞吐量。指一组并发任务中已完成任务所占的比例。
2. 响应性。指请求从发出到完成之间的时间（也称为延迟）
3. 可伸缩性。指在增加更多资源的情况下，吞吐量（或者缓解短缺）的提升情况。

#### 什么是可伸缩性？
可伸缩性是指：当增加计算资源时（CPU、内存、存储容量或 I/O 带宽），程序的吞吐量或者处理能力能相应地增加。

#### Amdahl 定律是什么？对性能或可伸缩性有什么启示作用？
在此之前，首先要明确，程序从理论上是由串行组件和可并行组件两部分组成。
而 Amdahl 定律描述的是：在增加计算资源的情况下，程序在理论上能够实现最高加速比，这个值取决于程序中可并行组件与串行组件所占的比重。假定 F 是必须被串行执行的部分，那么根据 Amdahl 定律，在包含 N 个处理器的机器中，最高的加速比为：
```
   SpeedUp ≤ 1 / (F + (1 - F) / N)
```
当 N 趋近无穷大时，最大的加速比趋近于 1/F。因此，如果程序有 50% 的计算需要串行执行，那么最高的加速比只能是 2。（而不管有多少个线程可用）。

Amdahl 定律告诉我们，程序的可伸缩性主要受程序中串行组件所占的比重的影响。要提高可伸缩性，就要尽量减小串行组件所占比重。

##### 减小串行组件比重的解决方案有哪些？
1. 在软件级别上，减小锁的竞争。在并发程序中，对可伸缩性的最主要威胁就是独占方式的资源锁。有两个因素将影响在锁上发生竞争的可能性。
   1. 锁的请求频率。
   2. 每次持有该锁的时间。
2. 在硬件级别上，减小总线争用的竞争。

#### 如何检测 CPU 的利用率？
常用的检测工具在 UNIX 上有 vmstat 和 mpstat，Windows 系统的 perfmon。都能给出 CPU 的忙碌状态。如果 CPU 没有得到充分利用，通常有以下几种原因：
+ 负载不充足。测试的程序中可能没有足够多的负载。因为可以在测试时增加负载，并检查利用率，响应时间和服务时间等指标的变化。
+ I/O 密集。可以通过 iostat 和 perfmon 来判断某个应用程序是否是磁盘 I/O 密集型的，或者通过监测网络的通信流量级别来判断它是否需要高带宽。
+ 外部限制。如果应用程序依赖于外部服务，可以使用某个分析工具来判断在等待外部服务的结果时需要多少时间。
+ 锁竞争。使用分析工具可以知道在程序中存在何种程度的锁竞争，以及在哪些锁上存在激烈的竞争。比如，通过线程转储信息中是否存在相应的栈帧包含信息如：“waiting to lock monitor..."。非竞争的锁很少会出现在线程转储中，而对于竞争激烈的锁，通常至少会有一个线程在等待获取它。因此将在线程转储时频繁出现。


> 局部性原理等待相关 FAQ

### 线程相关 FAQ

#### Java 中的线程有哪些状态？JVM 线程状态有哪些？操作系统的线程有哪些状态？
+ Java 中的线程是 6 个状态。分别是
  + NEW。Thread 被创建了，但是还没有调用 start() 方法的状态。
  + RUNNABLE。线程启动了之后的状态。可能是处于正在运行，也有可能是等待 CPU 调度。
  + BLOCKED。是指在等待获取锁的状态，包括从 wait 方法调用后移交到同步队列之后的状态。
  + WAITING。是指调用 wait、join、park 之后的等待状态。
  + TIMED_WAITING。是指 WAITING 状态的限期等待状态。
  + TERMINATED。线程执行完成之后的状态。
+ JVM 线程状态有多种。和 Java Thread 状态的关系是 sun.misc.VM.toThreadState。可通过该方法转换。Thread 类中有一个 threadStatus 属性描述的是 jvm 的线程状态。
+ 操作系统的线程七状态模型。分别是。
  + 创建状态。创建过程中，还不能运行。操作系统为其分配 TCB 控制块，填写相关内容。为线程分配线程组，连接线程的父子关系；为线程分配所需的资源和地址空间。当把创建好的进程移入就绪队列时，进程从创建状态转化为就绪状态。
  + 就绪状态。即进程已经获得了除处理机之外的所有必要资源，只要获得处理机就可以运行的状态。
  + 运行状态。进程正在处理机上运行的状态。
  + 阻塞状态。当进程由于等待输入输出操作或某个同步事件而暂停运行时，就处于阻塞状态。
  + 退出状态。进程正常或异常结束，操作系统首先要将该进程从运行状态移除，使之成为一个不可能再运行的进程，相应地使进程处于退出状态，并收回其所占的资源。
  + 就绪挂起状态。为了缓和内存紧张的情况，将内存中处于阻塞或者就绪状态的进程换至外存。
  + 阻塞挂起状态。同上，指示在阻塞状态时被挂起。

#### 在 Thread 类中，与中断有关的方法有哪些？分别提供什么功能？
1. interrupt(). Thread 实例方法，设置中断状态。在响应状态的地方能检测到并中断线程。这也是在语言层面唯一设置中断状态的方法。
2. isInterrupted(). Thread 实例方法。查询目标线程的中断状态。
3. static interrupted(). Thread 静态方法。清除当前线程的中断状态，并返回它之前的值，这也是清除中断状态的唯一方法。

#### 线程为什么需要中断？中断操作如何起作用的？
+ 通常，中断是实现取消的最好方式。
+ 中断操作并不会真正地中断一个正在运行的线程，而只是发出中断请求，然后由线程在下一个合适的时刻中断自己。（这些时刻也被称为取消点）。

#### 接收到 InterruptedException 之后，有几种处理方式？
通常由三种处理方式，描述如下。
1. 将方法声明为可阻塞的，将接收到的 InterruptedException 继续往上抛出去。此方法也有两种做法，一是直接向上抛出去，二是在方法内部记录当前中断状态，并在方法执行完之后检测中断状态然后再抛出去。（第二种通常是要在循环中完成一个步骤，不方便直接抛出去）。
2. 将方法声明为不可阻塞的，即不会向上抛出去 InterruptedException。接收到 InterruptedException 之后，使用 Thread.currentThread.interrupt() 恢复中断状态，然后由调用栈的上层代码通过 Thread.currentThread.isInterrupted() 以决定是否要对中断进行处理。
3. 捕获 InterruptedException 直接做处理（不作处理也是一种处理）。这种方式通常由实现了线程中断策略的代码来实现。

#### 什么是中断策略？
最合理的中断策略是某种形式的线程级取消操作或服务级取消操作: 尽快退出，在必要时进行清理，通知某个所有者该线程已经退出。此外还可以建立其他的中断策略，例如暂停服务或重新开始服务，但对于那些包含非标准中断策略的线程或线程池，只能用于能知道这些策略的任务中。

#### Java 中有哪些方法可能抛出中断异常？
+ 阻塞库相关方法。例如 Thread.sleep, Object.wait/join 等，都会检查线程何时中断，并且在发现中断时提前返回。它们在响应时执行的操作包括：清除中断状态，抛出 InterruptedException，表示阻塞操作由于中断而提前结束。JVM 并不能保证阻塞方法检测到中断的速度，但在实际情况中响应速度还是非常快的。

#### 停止基于线程的服务有哪些方式？
1. 如果服务是单线程的方式，则可以使用中断线程的方式来关闭线程的执行。当然，服务必须要实现响应中断的方式。
2. “毒丸”（Poison Pill）对象的使用。生产者向服务的阻塞队列中生产毒丸，而消费者接到毒丸后，根据毒丸的毒性来决定何时停止服务。
3. 如果是线程池 ExecutorService，如果指示停止某个任务，可以使用 submit 提交返回的 FutureTask 来实现取消。如果需要停止整个线程池服务，则可以使用 shutdown() or shutdownNow() 来关闭服务。

#### 如何处理线程中的未捕获异常
通过 Thread.setUncaughtExceptionHandler 设置线程未终止异常的处理。如果没有设置，默认行为是将栈追踪信息输出到 System.err。

### 线程池相关 FAQ

> 在多线程编程中，软件开发者常用一种“三级模式”，即处理器 - 调度器(线程) - 任务 三级模式。其中调度器通常是线程池，将任务的提交过程和执行过程分离开来，更好的进行资源管理。

#### 为什么需要线程池这种组件？
1. 将任务的提交过程和执行策略解耦分离，使得修改执行策略不会影响到提交过程。
2. 进行有效的资源管理，防止无限制的线程增长。线程无限制的增长缺陷主要有
   1. 线程生命周期的开销非常高。线程的创建和销毁需要消耗资源，当无限制的为每个请求都创建一个新线程将消耗大量的计算资源。
   2. 资源消耗。活跃的线程会消耗系统资源，特别是内存。如果可运行的线程数量多余可用处理器的数量，那么有些线程会闲置。大量空闲的线程会占用许多内存。
   3. 稳定性。在大多数平台上，可创建的线程数量均存在一个限制。如果破坏了这些限制，将会引发 OutOfMemoryError 异常。

#### 能不能所有的任务都使用一个线程池，或者除了 UI 任务外，其他任务都使用同一个线程池？使用线程池有什么建议和规范?
1. 第一个问题和第二个问题属于同一个问题，答案是不要这么做。
2. 第三个问题问的是对前面两个问题的答案的解释。在实际中，只有当任务都是同类型的并且相互独立的，才建议使用同一个线程池，此时，线程池的性能才能达到最佳。如果将运行时间较长的任务和时间较短的任务混合在一起，那么除非线程池很大，否则将可能造成某些任务饥饿的问题发生。即某些线程一直在忙着导致另一些任务得不到执行而拥塞。另外，如果提交的任务依赖于其他任务，除非线程池无限大，否则有可能发生阻塞。总而言之，区分任务的类型以及根据其需要使用不同的执行策略。

#### 线程池大小设置多少合适？设置不合适有什么后果？
+ 一般需要分析其计算环境、资源预算和任务的特性。比如机器的处理器个数、以及任务的类型（任务的等待时间和计算时间之比）、期望的 CPU 利用率、等条件来设置线程池大小。假设机器处理器核心数为 N，期望 CPU 利用率为 U, 任务等待时间为 W，计算时间为 C。
  + 如果是计算密集型任务，线程池大小一般分配为 N + 1 比较合适。多一个线程是为了防止缺页故障或其他错误导致线程暂停，这个额外的线程可以充分地提高资源利用率。
  + 如果是 I/O 密集型或者其他阻塞操作的任务，一般会需要比较大的线程池，因为其线程并不会一直执行。比如 Executors.newCachedThreadPool().
   推荐线程池大小计算公式为：
   ```
      N(thread) = N(CPU) * U * (1 + W/C )
   ```

   这个公式告诉我们，如果我们期望 CPU 的利用率越高，任务的阻塞性越强（即依赖 CPU 越弱），则需要分配的线程池就要尽可能的大。

   另外，除了纯考虑任务本身之外，在实践中，能分配的最大线程数往往还需要受限于内存、资源池的大小、文件句柄、套接字句柄和数据库连接等。

+ 如果线程池设计过大，则可能引起大量线程在相对较少的 CPU 或者内存资源上发生竞争。不仅会导致更高的内存使用量，还可能耗尽资源。如果线程池过小，则可能导致许多的空闲的处理器，浪费了资源，从而降低了系统吞吐量。

#### Java 线程池有哪些参数可以配置？
核心线程数大小、最大线程数大小、饱和策略、阻塞队列类型、线程工厂。

#### Java 线程池中，提供了哪几种饱和策略？
+ 中止策略（Abort) 是默认的饱和策略。该策略将抛出未检查的 RejectedExecutionException。调用者可以捕获这个异常，然后自己处理。
+ 抛弃策略（Dicard）。将会悄悄的抛弃该任务。
+ 抛弃最旧策略（Discard-Oldest）。将会抛弃下一个将被执行的任务，然后尝试重新提交新的任务。
+ 调用者运行策略（Caller-Runs）。该策略实现了一种调节机制，该策略既不会抛弃任务，也不会抛出异常，而是将任务回退到调用者，从而降低新任务的流量。

#### 在使用线程池的 web 服务中，如何实现限流？以及性能的优雅降级？
1. 饱和策略可以使用调用者执行策略。由于调用者执行任务需要一定的时间，因此主线程至少在一段时间内不能提交新任务，从而使得工作者线程有时间来处理完正在执行的任务。在这期间，主线程不会接收新的 web 请求，因为到达的请求将被保存在 TCP 层的队列中而不是在应用程序的队列中。如果持续过载，那么 TCP 层将最终发现它的请求队列被填满，因此同样会开始抛弃请求。当服务器过载时，这种过载情况会逐渐向外蔓延开来。也就是说从线程池到工作队列到应用程序再到 TCP 层，最终到达客户端，使得服务器在高负载下实现一种平缓的性能降低。

#### ExecutorService 的 shutdown() 和 shutdownNow() 有什么区别？
+ shutdown() 是平缓的关闭，它会取消空闲的工作线程并且阻止任务再提交。但会让已经提交的任务继续进行。
+ shutdownNow() 则会立即关闭。它会取消所有工作线程并且中断当前正在执行任务的线程，如果正在运行的任务响应中断，那么它会被终止，并且随后线程也会被终止。另外，shutdonwNow() 还会返回所有已经提交但尚未开始的任务。值得注意的是，如果不做特殊处理，那么 shutdownNow() 是无法知道哪些是已经开始运行但尚未执行完成的任务。（除非任务自己执行某种检查）

#### 程序设计中，任务需要被取消可能会有哪些原因？
1. 用户请求取消。例如用户点击 GUI 提供的“取消”按钮。
2. 有时间限制的操作。例如某个应用程序需要在有限时间内搜索问题空间，并在这个时间内选择最佳的解决方案。当计时器超时时，需要取消所有正在搜索的任务。
3. 应用程序事件。例如，应用程序对某个问题空间进行分解并搜索，从而使不同的任务可以搜索问题空间中的不同区域。当其中一个任务找到了解决方案时，所有其他仍在搜索的任务都将被取消。
4. 错误。比如应用程序执行某任务发生错误时（比如磁盘空间已满），那么可能需要取消任务。
5. 关闭。当应用程序关闭时，必须对正在处理和等待处理的工作执行某种操作。在平缓的关闭过程中，当前正在执行的任务将继续执行直到完成，而在立即关闭过程中，当前任务则可能取消。

#### 在 Java 中，延迟任务和周期任务的实现方式有哪些？它们各自的特点是？在使用建议上有什么区别？
延迟任务和周期任务的实现方式主要有 Timer 和 ScheduledThreadPoolExecutor。

Timer 的特点是。
1. 所有任务均通过小顶堆无界优先队列排队，一个线程 TimerThread 轮询优先队列，将其最靠前的任务（即绝对值时间最近的任务）先执行。所有任务在 TimerThread 均是串行执行。
2. 如果 TimerTask 抛出了一个未检查的异常，TimerThread 将会终止，并且不会恢复运行。此种情况下，已经被调度但尚未执行的 TimerTask 将都不会被执行。新的任务也不能被调度。

ScheduledThreadPoolExecutor 的特点是。
1. 其任务队列依然采用了小顶堆的无界优先队列，但是其可以指定 corePoolSize 大小来指定多线程的执行方式，即一个 Task 的运行可以不影响到另一个任务的运行。
2. 由于继承自 ThreadPoolExecutor，其一个任务的异常终止不会影响到其他任务的执行。

#### CompletionService 有什么作用？
CompletionService 提供了管理一组 FutureTask 的接口，具体实现参考 ExecutorCompletionService，其提供了提交任务的代理 Executor，以及使得一组 FutureTask 可并行执行，先得到结果的 Task 存放至一个 BlockingQueue，调用者可通过 take() 方法等待获取先返回来的任务。

### Java 并发库相关 FAQ

#### Barrier 和 CountDownLatch 的区别
1. Barrier 关注的是线程计数。一般来说 Barrier 允许重置以反复使用。
2. CountDown 关注的是事件计数。事件完成后即不可重复使用。

#### ConcurrentLinkeQueue 在 Java5、Java7、Java8 有什么区别？版本演进的目标是？

#### ConcurrentHashMap 在 Java5 和 Java8 的区别。

##### ConcurrentHashMap 的 get 方法是无锁的，那么它是怎么保证读线程和写线程是线程安全的呢？
+ 在 ConcurrentHashMap 5 中，通过 volatile 的 count 字段实现的线程安全性。每一个分段区间内都维护了一个 volatile 的 count 字段。并且其文档要求，在所有的对 table 的写操作最后都必须更新 count 字段，而所有对外提供的读取操作实现中，第一个动作就是要先读取 volatile 修饰的 count 字段。由于 volatile 语义保证，所以对 volatile 字段的写之前发生的动作，都会在 volatile 读操作之前发生，所以 volatile 读及其之后的读取操作会看见最新 table。并且由于在 ConcurrentHashMap 5 中，采用的是头插法，且其结点的 next 属性是 final 的，所以能够保证遍历过程中的读和写的安全性。仅有一个结点中的值 value 是 volatile 的，在它构造完毕后，其他线程可能看见过，对此，也采取了上锁操作来提供线程安全性。
+ 在 ConcurrentHashMap 8 中，分为三个方面来实现整体读和写的安全性
  + 在哈希桶中，对其数组元素的访问通过 Unsafe.getObjectVolatile 和 putObjectVolatile 其语义和 volatile 类似。也是对数组元素的写动作 happens-before 对数组元素的读。当被访问的元素被哈希映射到一个空桶中时，通过该方法来提供其安全性。
  + 运用尾插法，并在结点中使用 volatile 的 next 属性来提供安全性。当被访问的元素被哈希映射到一个不是空桶且不存在扩容冲突时。该方法用来提供这种情况的安全性。
  + 当被映射到的桶正在发生扩容且元素在新表位置确定时，通过一个占位结点，并通过占位结点找到新表进行安全性访问。当正在发生扩容且元素所在链表在新表位置没有完全确定时，依然读取旧表，并且在扩容时，旧表元素不会被删除。也就是说，移动完成之后就读新表。移动完成之前读旧表。通过在头部插入 ForwordingNode 结点来提供安全性。

另外简单提一下。不管是哪个版本的 ConcurrentHashMap，对于映射到同一个桶的两个写线程是通过锁来实现互斥的。虽然其最终提供的可伸缩性不同。Java 5 固定 16 个桶，而 Java 8 是每个链表的头结点作为锁。

#### ReentrantReadWriteLock FAQ
##### ReentrantReadWriteLock 的读线程和写线程是怎么保证线程安全的？
+ 其虽然用了两个锁，ReadLock，WriteLock。以实现读读共享，读写互斥、写写互斥。然而其 ReadLock 和 WriteLock 都公用了一个 Sync 同步器，其共同操作一个 volatile 的 state 变量。高 16 位为共享锁（读锁计数），低 16 位 为独占锁。利用 volatile 语义，可以实现基本的读写互斥。

##### ReentrantReadWriteLock 是读者优先还是写者优先还是完全公平策略？

##### ReentrantReadWriteLock 如何实现写锁降级？

### JMM FAQ

#### 什么是数据竞争？
当一个变量被多个线程读取并且至少被一个线程写入时，如果在读操作和写操作之间没有依照 Happens-before 来排序，那么就会产生数据竞争问题。